## Introduction

The run_analysis.R file contains the scripts that did the following steps of data cleaning:
- Merged the training and the test sets to create one data set.
- Extracted only the measurements on the mean and standard deviation for each measurement.
- Used descriptive activity names to name the activities in the data set.
- Appropriately labeled the data set with descriptive variable names.
- From the data set in step 4, created a second, independent tidy data set with the average of each variable for each activity and each subject.

## Data Cleaning Steps

### Preparation
The data files, label files, variable files and subject files were read into R. The files that were read in were:
- X_test.txt It contained the test data that was generated by 30% of the volunteers. The test data was referred as "test" in the scripts.
- X_train.txt It contained the training data that was generated by 70% of the volunteers. The training data was referred as "train" in the scripts.
- y_test.txt It contained the number of the activities that the subjects performed. The file was reffered as "testlabel" in the scripts.
- y_train.txt It contained the number of the activities that the subjects performed. The file was reffered as "trainlabel" in the scripts.
- activity_labels.txt It contained the names of the activities that were monitered by the experiment. The file was referred as "activitylabel" in the scripts.
- features.txt It contained the names of features that were selected for this database. The file was referred as "features" in the scripts.
- subject_test.txt It contained the IDs for the subjects that were in the test data. The file was referred as "testsub" in the scripts.
- subject_train.txt It contained the IDs for the subjects that were in the training data. The file was referred as "trainsub" in the scripts.

### Step1: Merged the training and the test sets to create one data set
First, added the subject IDs ("testsub", "trainsub") and the activity numbers ("testlabel", "trainlabel") to the "test" and "train" datasets respectively using cbind() function. The resulting datasets were called "testall" and "trainall".

Second, since the entire dataset was randomly partitioned into two sets: the training dataset and the test dataset, to get one dataset, we could use the rbind() function to combine the "testall" and "trainall" datasets together. The scripts showed to append the "testall" dataset to the end of the "trainall" dataset. The entire dataset was called "all".

Third, added variable names to each column of the "all" dataset using the colnames() function. The variable names for the features came from the "features" dataset. The value type of the "features" dataset was changed from factor to character. The first column of the "all" dataset was named as "subjectid", and the second column of the "all" dataset was named as "numberofactivity". So every column in the "all" dataset had a variable name. 

### Step2: Extracted only the measurements on the mean and standard deviation for each measurement
Only the variables that contained "mean()" and "std()" in their names would be retained in the subset dataset. Some variables contained "meanFreq()" in their names; those variables would not be retained in the subset dataset as they were not considered as mean and thus calculated differently from the mean value.

Variables containing "mean()" and "std()" in their names were searched by using the grep() function. Since the parentheses "()" can serve as a metacharacter, the escape sign \\ had to be used to tell R that the parentheses here served as literal parentheses. A subset of variables that met the requirements was stored in a vector called "subsetvar".
 
Subset the "all" dataset to only include the desired columns. The subset dataset was referred as "subsetall".

### Step3: Used descriptive activity names to name the activities in the data set
The "activitylabel" file tells the activity name that each number, from 1 to 6 represents. Recoded the "numberofactivity" variable in the "subsetall" dataset according the "activitylabel" file.

### Step4: Labeled the data set with descriptive variable names
I understood this step as to spell out all the acronyms in the variable names, so the variable names were explicit. Therefore, the "t", "f", "Acc", "Gyro" and "Mag" in the variable names were spelt out. "mean" and "std" are pretty explicit to most of the people, so they were not spelt out fully. The hypens in the variable names were left as is as they didn't impede reading or interpretation.

The dplyr library was loaded in order to use the rename() function. The sub() function was used to replace the acronyms with the full names.

### Step5: Created a second, independent tidy data set with the average of each variable for each activity and each subject
To get the average of each variable for each activity and each subject, the "subsetall" dataset has to be grouped by subject IDs first and then by activity types. The aggregate() function took multiple variables (subsetall$subjectid, subsetall$activity) as the grouping variable and apply the function (mean) to multiple columns. The new dataset was referred as "UCIHARFinal".

After applying the aggregate() function, the variables of "subjectid" and "activity" were changed to Group.1 and Group.2 in the "UCIHARFinal" dataset, which were not explicit. As a result, these two variables were renamed back to "subjectid" and "activity" using rename() function. 

The "UCIHARFinal" dataset has 180 rows and 68 variables. The variables are "subjectid", "activity", and 66 feature variables. These variables were explained in the CodeBook.md file.

At last, the "UCIHARFinal" dataset was written out as a .txt file to the working directory using the write.table() function.